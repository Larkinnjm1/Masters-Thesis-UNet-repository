{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libs\n",
    "\n",
    "### please update Albumentations to version>=0.3.0 for `Lambda` transform support\n",
    "!pip install -U albumentations>=0.3.0 --user \n",
    "!pip install -U --pre segmentation-models --user\n",
    "#This installation command is to resolve issues with respect to efficient not being found in the initila build of segmentation modle sm \n",
    "!pip install -U git+https://github.com/qubvel/segmentation_models\n",
    "#uPGRADE SCKITI IMAGE\n",
    "!pip install --upgrade scikit-image\n",
    "#RESTART THE KERNEL POST INSTALLATION\n",
    "#This is to resolve the dependency issues with skimage. \n",
    "!pip install numpy==1.17\n",
    "!pip install ipdb\n",
    "!pip install pandas_ml\n",
    "!pip install nibabel pydicom medpy\n",
    "!pip install seaborn -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "#RESTART THE KERNEL POST INSTALLATION of cell above\n",
    "import os\n",
    "\n",
    "#Confirmation that GPU is in working order. \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from medpy.io import load as load_segcaps\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import albumentations as A\n",
    "import random\n",
    "import segmentation_models as sm\n",
    "import datetime\n",
    "import itertools\n",
    "from sklearn.utils import class_weight\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ipdb\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "from keras.models import load_model\n",
    "from scipy.spatial import distance\n",
    "from collections import OrderedDict\n",
    "from keras import backend as K_b\n",
    "import shutil\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "from medpy.io import load\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir='/home/ec2-user/SageMaker/data/50_imgs/test/NIFTI_MR_256x256_png_256grey_lvl/t1dual_inphase'\n",
    "train_data_dir='/home/ec2-user/SageMaker/data/50_imgs/train/NIFTI_MR_256x256_png_256grey_lvl/t1dual_inphase'\n",
    "valid_data_dir='/home/ec2-user/SageMaker/data/50_imgs/valid/NIFTI_MR_256x256_png_256grey_lvl/t1dual_inphase'\n",
    "#Destination directory\n",
    "dst_dir='/home/ec2-user/SageMaker/data/250_imgs/merge/NIFTI_MR_256x256_png_256grey_lvl/t1dual_inphase'\n",
    "x_dst_dir = os.path.join(dst_dir, 'images')\n",
    "y_dst_dir = os.path.join(dst_dir, 'masks')\n",
    "paths_merge=list(zip(glob.glob(x_dst_dir+'/*.png'),\n",
    "                     glob.glob(y_dst_dir+'/*.png')))\n",
    "x_test_dir = os.path.join(test_data_dir, 'images')\n",
    "y_test_dir = os.path.join(test_data_dir, 'masks')\n",
    "\n",
    "x_train_dir = os.path.join(train_data_dir, 'images')\n",
    "y_train_dir = os.path.join(train_data_dir, 'masks')\n",
    "\n",
    "x_valid_dir = os.path.join(valid_data_dir, 'images')\n",
    "y_valid_dir = os.path.join(valid_data_dir, 'masks')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging of test/train and validation data for running per image prediction using keras prediction generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_merge=[x_train_dir,x_test_dir,x_valid_dir]\n",
    "y_merge=[y_train_dir,y_test_dir,y_valid_dir]\n",
    "\n",
    "for x_dir,y_dir in list(zip(x_merge,y_merge)):\n",
    "    \n",
    "    x_file_list=glob.glob(x_dir+'/*.png')\n",
    "    y_file_list=glob.glob(os.path.join(y_dir,'*.png'))\n",
    "\n",
    "    [shutil.copy(x_tmp,os.path.join(x_dst_dir,os.path.basename(x_tmp))) for x_tmp in x_file_list]\n",
    "    [shutil.copy(y_tmp,os.path.join(y_dst_dir,os.path.basename(y_tmp))) for y_tmp in y_file_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing of all images to match 256,256 size resolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vals in paths_merge:\n",
    "    trl_img=imageio.imread(vals[0])\n",
    "    trl_mask=imageio.imread(vals[1])\n",
    "    \n",
    "    #trl_imgs_set={vals[0]:resize_img_PIL(trl_img),vals[1]:resize_img_PIL(trl_mask)}\n",
    "    #ipdb.set_trace()\n",
    "    #[imageio.imwrite(k,v) for k,v in trl_imgs_set.items() if type(v) is not str]\n",
    "    if trl_mask.shape!=(256,256):\n",
    "        print(vals[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble shooting area of test dataset and model loads to ensure generators are working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.6/site-packages/albumentations/augmentations/transforms.py:2908: UserWarning: Using lambda is incompatible with multiprocessing. Consider using regular functions or partial().\n",
      "  \"Using lambda is incompatible with multiprocessing. \"\n"
     ]
    }
   ],
   "source": [
    "test_dataset=gen_test_dataset(dst_dir,model_gnrl_params,preprocess_input,pred_gen_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['l_kidney','liver','r_kidney','spleen']\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    x_dst_dir, \n",
    "    y_dst_dir, \n",
    "    classes=CLASSES,\n",
    "    preprocessing=get_preprocessing(preprocess_input),\n",
    "    augmentation=get_validation_augmentation(),ret_img_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local parameters for analysis\n",
    "lcl_wghts_dir='/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks/weights_history_full/cat_focal_loss/btch_sz_7/lr_0.0003/weights/t1dual_inphase_all_orgs_grey_lvl_256_optm_Adam_loss_cat_focal_loss_trn_samp_sz_250_btch_sz_7_lr_0.0003_time_2019-11-18_00000096.h5'\n",
    "lcl_wghts_dir_2='/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks/weights_history_full/cat_focal_loss/btch_sz_7/lr_0.0003/weights/t1dual_inphase_all_orgs_grey_lvl_256_optm_Adam_loss_cat_focal_loss_trn_samp_sz_250_btch_sz_7_lr_0.0003_time_2019-11-18_00000093.h5'\n",
    "\n",
    "optimiser_tmp=keras.optimizers.Adam(0.0003)\n",
    "total_loss_tmp=sm.losses.CategoricalFocalLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processsing time: 32.6539204120636\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "model_tmp=gen_test_model(model_gnrl_params,optimiser_tmp,total_loss_tmp,lcl_wghts_dir_2)\n",
    "end_time=time.time()-start_time\n",
    "print('processsing time:',end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processsing time: 19.25001549720764\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "output=model_tmp.predict_generator(test_dataset,steps=len(test_dataset))\n",
    "end_time=time.time()-start_time\n",
    "print('processsing time:',end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trl_path=os.path.join(x_dst_dir,\n",
    "                      'pat_id_38_t1dual_inphase_slice_no_21_256grey_lvl_256x256.png')\n",
    "trl_img=imageio.imread(trl_path)\n",
    "trl_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,mask,img_nm=test_dataset[1]\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading function calls for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader and dataset functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_img_PIL(img:np.ndarray,shp_sp=(256,256)):\n",
    "    \n",
    "    if img.shape!=shp_sp:\n",
    "        PIL_img=Image.fromarray(img)\n",
    "        np_img_reshp=np.array(PIL_img.resize(shp_sp))\n",
    "        \n",
    "        return np_img_reshp\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "# helper function for data visualization\n",
    "def visualize(fig_nm=None,figdim=(33,3.1),**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    print(fig_nm)\n",
    "    plt.figure(figsize=figdim)\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    \n",
    "    if fig_nm is not None:\n",
    "        plt.savefig(fig_nm,dpi=150)\n",
    "        plt.clf()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "    \n",
    "\n",
    "# classes for data loading and preprocessing\n",
    "class Dataset:\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = {'background':0,'liver':63,'r_kidney':126,'l_kidney':189,'spleen':252}\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "            ret_img_path=False\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES[cls.lower()] for cls in classes]\n",
    "        self.ret_img_path=ret_img_path\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = imageio.imread(self.images_fps[i])#cv2.imread(self.images_fps[i])\n",
    "        image_nm=os.path.basename(self.images_fps[i])\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image=np.expand_dims(image,axis=2)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == v) for v in self.class_values]\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "        if mask.shape[-1] != 1:\n",
    "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        if self.ret_img_path==True:\n",
    "            return image, mask,image_nm\n",
    "        else:\n",
    "            return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    \n",
    "class CustomDataloder(keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)   \n",
    "            \n",
    "def round_clip_0_1(x, **kwargs):\n",
    "    return x.round().clip(0, 1)\n",
    "\n",
    "# define heavy augmentations\n",
    "def get_training_augmentation(dim_sp=256):\n",
    "    \n",
    "    rand_int_alpha=random.uniform(0,3)\n",
    "    if rand_int_alpha<=0.5:\n",
    "        rand_int_sigma=random.uniform(0.1,rand_int_alpha)\n",
    "    elif rand_int_alpha>=2:\n",
    "        rand_int_sigma=random.uniform(rand_int_alpha/1.8,rand_int_alpha)\n",
    "    else:\n",
    "        rand_int_sigma=random.uniform(rand_int_alpha/1.8,rand_int_alpha)\n",
    "    train_transform = [\n",
    "        #A.RandomGridShuffle(p=0.4,grid=(8, 8)),\n",
    "        A.ElasticTransform(p=0.9,alpha=rand_int_alpha,sigma=rand_int_sigma,border_mode=cv2.BORDER_REPLICATE), #,alpha_affine=20\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        #A.RandomSizedCrop(p=0.5),\n",
    "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=90, shift_limit=0.1, p=0.5, border_mode=cv2.BORDER_REPLICATE),\n",
    "\n",
    "        #A.PadIfNeeded(min_height=dim_sp, min_width=dim_sp, always_apply=True, border_mode=cv2.BORDER_REPLICATE),\n",
    "        #A.RandomCrop(height=dim_sp, width=dim_sp, always_apply=True),\n",
    "\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.IAASharpen(p=0.5),\n",
    "                A.Blur(blur_limit=3, p=0.5)\n",
    "            ],\n",
    "            p=0.2,\n",
    "        ),\n",
    "\n",
    "        A.Lambda(mask=round_clip_0_1)\n",
    "    ]\n",
    "    return A.Compose(train_transform)\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
    "    test_transform = [\n",
    "        A.PadIfNeeded(256, 256)\n",
    "    ]\n",
    "    return A.Compose(test_transform)\n",
    "\n",
    "def get_preprocessing(preprocessing_fn):\n",
    "    \"\"\"Construct preprocessing transform\n",
    "    \n",
    "    Args:\n",
    "        preprocessing_fn (callbale): data normalization function \n",
    "            (can be specific for each pretrained neural network)\n",
    "    Return:\n",
    "        transform: albumentations.Compose\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    _transform = [\n",
    "        A.Lambda(image=preprocessing_fn),\n",
    "    ]\n",
    "    return A.Compose(_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_flow_from_dir(dst_dir,preprocess_input,\n",
    "                        target_size_var=(256, 256),batch_size_var=7):\n",
    "    \"\"\"Creation of template based keras image generator for batch scale prediction for efficient processing.\"\"\"\n",
    "    gen_test_2 =ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    \n",
    "    dst_dir=dst_dir+'_keras_dataloader' if dst_dir.find('_keras_dataloader')==-1 else dst_dir\n",
    "    \n",
    "    dataloader=gen_test_2.flow_from_directory(dst_dir,target_size=target_size_var,\n",
    "                                                batch_size=batch_size_var,\n",
    "                                                class_mode=None,color_mode='grayscale',shuffle=False)\n",
    "    \n",
    "    return dataloader\n",
    "    \n",
    "#tmp_v=test_dataset.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_subdir_file_lst(dir_nm:str,file_sub_str:str):\n",
    "    \"\"\"The purpose of this method is to generate a file list of all h5 weights sorted for completing batch prediction\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    final_list=[]\n",
    "    for root,subdir,files in os.walk(dir_nm):\n",
    "        if len(files)>0:\n",
    "\n",
    "            file_list=glob.glob(root+file_sub_str)\n",
    "            final_list=final_list+file_list\n",
    "    #Sorted to ensure history part 2,3 etc are synced together \n",
    "    return sorted(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_info(file,add_info):\n",
    "    \"\"\"The purpose of this method is to pull file information from the file name presnet in the string\"\"\"\n",
    "    #ipdb.set_trace()\n",
    "    split_vals=file[:-14].split('_')\n",
    "    split_vals.sort()\n",
    "    file_dict={}\n",
    "    #Iterate through additional information of set of tuples on file strings for analysis\n",
    "    for param_k,param_v in add_info:\n",
    "\n",
    "        file_dict[param_k]=[x for x in param_v if x in split_vals][0]\n",
    "    \n",
    "    file_dict['epoch_no']=99#int(split_vals[-1][:-3]) \n",
    "\n",
    "    return file_dict,split_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_dataset(test_data_dir,model_gnrl_params,preprocess_input,ret_img_path_var):\n",
    "    \n",
    "    x_test_dir=os.path.join(test_data_dir,'images')\n",
    "    y_test_dir=os.path.join(test_data_dir,'masks')\n",
    "    \n",
    "    return Dataset(x_test_dir, y_test_dir, \n",
    "                            classes=model_gnrl_params['classes'],\n",
    "                           augmentation=get_validation_augmentation(),\n",
    "                           preprocessing=get_preprocessing(preprocess_input),\n",
    "                   ret_img_path=ret_img_path_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate model and test model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_model(model_gnrl_param:dict,lrn_rate,total_loss,wghts_dir:str,cls_wghts_perc=None):\n",
    "    \"\"\"The purpose of this method is to generate a test model from the directory for analysis\"\"\"\n",
    "    \n",
    "    loss_func={'cat':sm.losses.CategoricalCELoss(class_weights=cls_wghts_perc),\n",
    "               'wce':sm.losses.CategoricalCELoss(class_weights=cls_wghts_perc),\n",
    "           'focal':sm.losses.CategoricalFocalLoss(),\n",
    "           'dice':sm.losses.DiceLoss(class_weights=cls_wghts_perc)}\n",
    "    \n",
    "    optim=keras.optimizers.Adam(lrn_rate)\n",
    "    \n",
    "    reload_model = sm.Unet(model_gnrl_param['backbone'], classes=model_gnrl_param['n_classes'],\n",
    "                           activation=model_gnrl_param['activation_type'],\n",
    "                           encoder_weights=None,\n",
    "                           input_shape=(None, None,model_gnrl_param['input_shape_N']))\n",
    "    \n",
    "    reload_model.compile(optim,loss_func[total_loss],model_gnrl_param['metrics'])\n",
    "\n",
    "    reload_model.load_weights(wghts_dir)\n",
    "    \n",
    "    return reload_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_scores(model,test_dataloader,metrics)->dict:\n",
    "    \"\"\"The purpose of this method is to generate a summary dictionary\n",
    "    of a model test set metrics for analysis\"\"\"\n",
    "    \n",
    "    metric_dict={}\n",
    "    \n",
    "    scores = model.evaluate_generator(test_dataloader)\n",
    "\n",
    "    metric_dict[\"loss\"]=scores[0]\n",
    "    for metric, value in zip(metrics, scores[1:]):\n",
    "        metric_dict[metric.__name__]=value\n",
    "        \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_per_class_dice_loss(y_true:np.ndarray,y_pred:np.ndarray,\n",
    "                            channel='channel_last',\n",
    "                            dice_dict=OrderedDict(left_kidney=0,liver=0,right_kidney=0,spleen=0,background=0))->dict:\n",
    "    \"\"\"The purpose of this method is to generate a dice loss for each organ within the logits present\"\"\"\n",
    "    assert y_true.shape==y_pred.shape,'Error predicted and ground tensors incorrect shape'\n",
    "    #ipdb.set_trace()\n",
    "    if channel=='channel_last':\n",
    "        channel_idx=2\n",
    "        assert y_true.shape[2]==len(dice_dict.keys()),'dictionary and prediction labels do not match'\n",
    "        tmp_dict={tup_st[0]:dice_score(y_true[:,:,i],y_pred[:,:,i]) for i,tup_st in enumerate(dice_dict.items())}\n",
    "    else:\n",
    "        channel_idx=0\n",
    "        assert y_true.shape[0]==len(dice_dict.keys()),'dictionary and prediction labels do not match'\n",
    "        tmp_dict={tup_st[0]:dice_score(y_true[i,:,:],y_pred[i,:,:]) for i,tup_st in enumerate(dice_dict.items())}\n",
    "        \n",
    "    return tmp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_true_arr,y_pred_arr):\n",
    "    \"\"\"Return single f1 score for mask image for specific class. \"\"\"\n",
    "    from sklearn.metrics import f1_score\n",
    "    \n",
    "    zero_sum_chk=np.count_nonzero(y_true_arr)+np.count_nonzero(y_pred_arr)\n",
    "    \n",
    "    if len(np.unique(y_true_arr))>2 or len(np.unique(y_pred_arr))>2:\n",
    "        print('non binary masks')\n",
    "        print(np.unique(y_true_arr))\n",
    "        print(np.unique(y_pred_arr))\n",
    "    \n",
    "    if zero_sum_chk==0:\n",
    "        return 'NaN no classes in image'\n",
    "    else:\n",
    "        #ipdb.set_trace()\n",
    "        return f1_score(y_true_arr.astype(np.int64).flatten(),\n",
    "                        y_pred_arr.astype(np.int64).flatten(),average='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_gen_dir(dst_dir_val):\n",
    "    if os.path.isdir(dst_dir_val)==True:\n",
    "        pass\n",
    "    else:        \n",
    "        try:\n",
    "            os.mkdir(dst_dir_val)\n",
    "        except FileNotFoundError as e:\n",
    "            print('creating a nested directory',dst_dir_val)\n",
    "            os.makedirs(dst_dir_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_images(tmp_model,test_dataset,file_dict:dict,model_dir,mode,test_dataloder=None):\n",
    "    \"\"\"Generate testing images for analysis\"\"\"\n",
    "    loss_func=file_dict['loss_type']\n",
    "    lrn_rate=file_dict['learn_rate']\n",
    "    epoch_no=str(file_dict['epoch_no'])\n",
    "    btch_sz=str(file_dict['btch_sz'])\n",
    "    dst_dir=os.path.join(model_dir,'predict_imgs',loss_func+'_btch_sz_'+btch_sz+'_lr_'+lrn_rate+'_epoch_no_'+epoch_no)\n",
    "    #Generating new paths based on conditional path function for nested paths \n",
    "    #ipdb.set_trace()\n",
    "    dst_dir_logits=os.path.join(dst_dir,'prob_logits')\n",
    "    dst_dir_imgs=os.path.join(dst_dir,'images')\n",
    "    [cond_gen_dir(x) for x in [dst_dir_logits,dst_dir_imgs]]\n",
    "    #Making a directory based on initial analysis\n",
    "    if mode=='per_img_visualise':\n",
    "        dice_score_lst=per_img_prediction_keras(test_dataset,tmp_model,dst_dir_imgs,dst_dir_logits,file_dict)\n",
    "    else:\n",
    "        dice_score_lst=per_batch_img_prediction_keras(test_dataset,test_dataloder,\n",
    "                                                      tmp_model,dst_dir_imgs,dst_dir_logits,file_dict)\n",
    "    #Summary path and dataframe\n",
    "    summary_path=os.path.join(dst_dir,'summary.csv')\n",
    "    tmp_df=pd.DataFrame(dice_score_lst)\n",
    "    tmp_df.to_csv(summary_path)\n",
    "    \n",
    "    return dice_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_batch_img_prediction_keras(test_dataset,test_dataloder,tmp_model,dst_dir_imgs,dst_dir_logits,file_dict):\n",
    "    \n",
    "    \n",
    "    dice_score_lst=[]\n",
    "    #Squeezing predicted images down to pass testing. \n",
    "    num_files=len(test_dataset)\n",
    "    no_of_batches=len(test_dataloder)\n",
    "    #Reseting test dataloader for each prediction to ensure consistent indexing\n",
    "    test_dataloder.reset()\n",
    "    img_nms_lst=test_dataloder.filenames\n",
    "    pr_masks = tmp_model.predict_generator(test_dataloder,steps=no_of_batches)\n",
    "    no_imgs=pr_masks.shape[0]\n",
    "    #Creating logit binary mask for prediction writing logit file as well to file\n",
    "    test_dataset_ids=test_dataset.ids\n",
    "    \n",
    "    for i in range(0,no_imgs):\n",
    "        #Generating image dataset and mask \n",
    "        #ipdb.set_trace()\n",
    "        img_nm=os.path.basename(img_nms_lst[i])\n",
    "        dst_img_path=os.path.join(dst_dir_imgs,'predict_binary_'+img_nm)\n",
    "        #Getting image mask from test dataset based on mask\n",
    "        gt_mask_idx=[i for i in range(0,num_files) if test_dataset_ids[i]==img_nm][0]\n",
    "        image,gt_mask,_=test_dataset[gt_mask_idx]\n",
    "        #Converting softmax logit to binary logit\n",
    "        pr_mask_sqz=write_logit_to_file(pr_masks[i,:,:,:],dst_dir_logits,img_nm)\n",
    "        #Writing final output to file\n",
    "        write_prediction_output(pr_masks[i,:,:,:],dst_dir_logits,\n",
    "                                img_nm,gt_mask,dst_img_path,image,file_dict)\n",
    "        \n",
    "        dice_loss_per_class=gen_full_dice_row(gt_mask,pr_mask_sqz,file_dict,img_nm)\n",
    "        \n",
    "        dice_score_lst.append(dice_loss_per_class)  \n",
    "        \n",
    "    return dice_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_img_prediction_keras(test_dataset,tmp_model,dst_dir_imgs,dst_dir_logits,file_dict):\n",
    "    \"\"\"Per image prediction script to write all images to file prediciting on a per image basis\"\"\"\n",
    "    num_files=len(test_dataset)\n",
    "    \n",
    "    dice_score_lst=[]\n",
    "    \n",
    "    for i in range(0,num_files):\n",
    "        #Generating image dataset and mask \n",
    "        image,gt_mask,img_nm=test_dataset[i]\n",
    "        dst_img_path=os.path.join(dst_dir_imgs,'predict_binary_'+img_nm)\n",
    "        #Getting images setup for testing\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        #Squeezing predicted images down to pass testing. \n",
    "        pr_mask = tmp_model.predict(image)\n",
    "        pr_mask_sqz_logit=pr_mask.squeeze()\n",
    "        #Creating logit binary mask for prediction writing logit file as well to file\n",
    "        \n",
    "        write_prediction_output(pr_mask_sqz_logit,dst_dir_logits,\n",
    "                                img_nm,gt_mask,dst_img_path,image,file_dict)\n",
    "        \n",
    "        dice_loss_per_class=gen_full_dice_row(gt_mask,pr_mask_sqz,file_dict,img_nm,file_dict)\n",
    "        \n",
    "        dice_score_lst.append(dice_loss_per_class)\n",
    "        \n",
    "    return dice_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_prediction_output(pr_mask_sqz_logit,dst_dir_logits,img_nm,\n",
    "                            gt_mask,dst_img_path,image,file_dict):\n",
    "    \n",
    "    pr_mask_sqz=write_logit_to_file(pr_mask_sqz_logit,dst_dir_logits,img_nm)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if file_dict['epoch_no']>96:\n",
    "    #Writing line of predicted images to file for analysis and verification. \n",
    "        visualize(dst_img_path,\n",
    "            image=denormalize(image.squeeze()),\n",
    "            gt_mask_l_kidney=gt_mask[:,:,0],\n",
    "            pr_mask_l_kidney=pr_mask_sqz[:,:,0],\n",
    "            gt_mask_liver=gt_mask[:,:,1],\n",
    "            pr_mask_liver=pr_mask_sqz[:,:,1],\n",
    "            gt_mask_r_kidney=gt_mask[:,:,2],\n",
    "            pr_mask_r_kidney=pr_mask_sqz[:,:,2],\n",
    "            gt_mask_spleen=gt_mask[:,:,3],\n",
    "            pr_mask_spleen=pr_mask_sqz[:,:,3],\n",
    "            gt_mask_background=gt_mask[:,:,4],\n",
    "            pr_mask_background=pr_mask_sqz[:,:,4],\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_full_dice_row(gt_mask:np.ndarray,pr_mask_sqz:np.ndarray,file_dict,img_nm)->dict:\n",
    "            #Generate dice loss per image\n",
    "    dice_loss_per_class=gen_per_class_dice_loss(gt_mask,pr_mask_sqz)\n",
    "    dice_loss_per_class['file_nm']=img_nm\n",
    "    dice_loss_per_class['loss_func']=file_dict['loss_type']\n",
    "    dice_loss_per_class['btch_sz']=float(file_dict['btch_sz'])\n",
    "    dice_loss_per_class['learn_rate']=float(file_dict['learn_rate'])\n",
    "    dice_loss_per_class['epoch_no']=float(file_dict['epoch_no'])\n",
    "    \n",
    "    return dice_loss_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_binarize(logit_arr):\n",
    "    \"\"\"The purpose of this method is to perform softmax binarisation of logit array \"\"\"\n",
    "    return np.where(logit_arr.max(axis=2,keepdims=True) == logit_arr,1,0).astype(np.float64)\n",
    "    \n",
    "def write_logit_to_file(pr_mask_sqz_logit,dst_dir_logits,img_nm):\n",
    "    \n",
    "    pr_mask_sqz=logit_binarize(pr_mask_sqz_logit)\n",
    "    dst_logit_path=os.path.join(dst_dir_logits,'predict_logit_'+os.path.splitext(img_nm)[0])\n",
    "    np.save(dst_logit_path,pr_mask_sqz_logit)\n",
    "    return pr_mask_sqz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_set_df(model_dir,test_data_dir,\n",
    "                    model_gnrl_param_dict,add_info,mode='Test',\n",
    "                    cls_wghts_perc_var=np.array([0.03987201, 0.36867433, 0.35872208, 0.2314718 , 0.00125978])):\n",
    "    \"\"\"The purpose of this method is to generate a \"\"\"\n",
    "    #Generating assertion \n",
    "    assert mode.lower() in ['test','batch_visualise','per_img_visualise'],'incorrect mode selection'\n",
    "    #ipdb.set_trace()\n",
    "    #Generating list of paths to models weights for analysis\n",
    "    model_weights_dir=gen_subdir_file_lst(model_dir,'/*.h5')\n",
    "    #Model weights directory\n",
    "    \n",
    "    #model_weights_dir=[x for x in model_weights_dir if x.find('focal')==-1]\n",
    "    model_weights_dir=[x for x in model_weights_dir if x.find('wce')==-1]\n",
    "    model_weights_dir=[x for x in model_weights_dir if x.find('cat_ce')==-1]\n",
    "    tmp_dice_lst_2=['dice','0.1','0.0003']\n",
    "    model_weights_dir=[x for x in model_weights_dir if len([y for y in tmp_dice_lst_2 if x.find(y)!=-1])<2]\n",
    "    #ipdb.set_trace()\n",
    "    #Generating dataset for analysis\n",
    "    preprocess_input = sm.get_preprocessing(model_gnrl_param_dict['backbone'])\n",
    "    test_dataset=gen_test_dataset(test_data_dir,model_gnrl_params,preprocess_input,ret_img_path_var=True)\n",
    "    if mode.lower()=='batch_visualise':\n",
    "        test_dataloader = keras_flow_from_dir(test_data_dir,preprocess_input)\n",
    "    elif mode.lower()=='test':\n",
    "        test_dataset=gen_test_dataset(test_data_dir,model_gnrl_params,preprocess_input,ret_img_path_var=False)\n",
    "        test_dataloader = CustomDataloder(test_dataset, batch_size=1, shuffle=False)\n",
    "    #ipdb.set_trace()\n",
    "    #Final json list to return for analysis\n",
    "    final_lst=[]\n",
    "    for fl_path in model_weights_dir:\n",
    "        print(fl_path)\n",
    "        #ipdb.set_trace()\n",
    "        #File path dictionayr information for analysis\n",
    "        file_dict,split_vals=get_file_info(fl_path,add_info)\n",
    "        #ipdb.set_trace()\n",
    "        #Generating specific parameters for laoding the model based on file nam\n",
    "        start_model=time.time()\n",
    "        #Load temporary model for analysis\n",
    "        tmp_model=gen_test_model(model_gnrl_param_dict,\n",
    "                                 float(file_dict['learn_rate']),\n",
    "                                 file_dict['loss_type'],fl_path,cls_wghts_perc_var)\n",
    "        finish_model=time.time()\n",
    "        \n",
    "        #Test model based on dataset and analysis\n",
    "        if mode.lower()=='test':\n",
    "            \n",
    "            tmp_score_dict=gen_test_scores(tmp_model,test_dataloader,model_gnrl_params['metrics'])\n",
    "            file_dict.update(tmp_score_dict)\n",
    "            final_lst.append(file_dict)\n",
    "        else:\n",
    "            #ipdb.set_trace()\n",
    "            start=time.time()\n",
    "            tmp_lst=gen_test_images(tmp_model,test_dataset,file_dict,model_dir,mode,test_dataloader)\n",
    "            finish=time.time()\n",
    "            print('total time loading model:',finish_model-start_model)\n",
    "            print('total time predicting images:',finish-start)\n",
    "            #Merging list of dictionaries for analysis\n",
    "            final_lst=final_lst+tmp_lst\n",
    "            #print(pd.DataFrame.from_dict(tmp_lst[:10]))\n",
    "        K_b.clear_session()\n",
    "        \n",
    "    return final_lst\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load initial parameters for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading arguments for analysis\n",
    "#'efficientnetb3'densenet121\n",
    "#BATCH_SIZE = 3\n",
    "CLASSES = ['l_kidney','liver','r_kidney','spleen']\n",
    "\n",
    "activation = 'sigmoid' if len(CLASSES) == 1 else 'softmax'\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "cls_wghts_perc=np.array([0.03987201, 0.36867433, 0.35872208, 0.2314718 , 0.00125978])\n",
    "#Getting keys for different analysis types\n",
    "add_info=[('learn_rate',['0.0003','0.001','0.01','0.1']),\n",
    "          ('samp_sz',['500','250','50']),('btch_sz',['3','7']),\n",
    "          ('loss_type',['dice','focal','wce'])]\n",
    "\n",
    "model_gnrl_params={'backbone':'resnet101','n_classes':len(CLASSES)+1,\n",
    "                   'metrics':metrics,'input_shape_N':1,\n",
    "                   'activation_type':activation,'classes':['l_kidney','liver','r_kidney','spleen']}\n",
    "#Generating weights directory for iterating for analysis\n",
    "#Directory lists \n",
    "model_dir='/home/ec2-user/SageMaker/data/unet_data_aug_modified_results/data_aug_all_param_reducd_50perc/cat_focal_loss/btch_sz_3/lr_0.001/final_epch_wghts'                    \n",
    "test_data_dir='/home/ec2-user/SageMaker/data/250_imgs/merge/NIFTI_MR_256x256_png_256grey_lvl/t1dual_inphase'\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(model_gnrl_params['backbone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trl_ls=[]\n",
    "for vals in model_weights_dir:\n",
    "    tmp_dict={}\n",
    "    val_split=vals.split('/')\n",
    "    tmp_dict['lrn_rate']=val_split[-3]\n",
    "    tmp_dict['btch_sz']=val_split[-4]\n",
    "    tmp_dict['loss']=val_split[-5]\n",
    "    trl_ls.append(tmp_dict)\n",
    "    \n",
    "trl_df=pd.DataFrame(trl_ls)\n",
    "#trl_df.drop_duplicates(inplace=True)\n",
    "trl_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results=get_test_set_df(model_dir,test_data_dir,\n",
    "                              model_gnrl_params,add_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df=pd.DataFrame.from_dict(model_results)\n",
    "model_df.to_csv('unet_model_test_data_summary_results_05_11_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>btch_sz</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>iou_score</th>\n",
       "      <th>learn_rate</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>samp_sz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0.697137</td>\n",
       "      <td>0.664423</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.016060</td>\n",
       "      <td>focal</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>0.668877</td>\n",
       "      <td>0.641736</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>focal</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.630676</td>\n",
       "      <td>0.611101</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.024256</td>\n",
       "      <td>focal</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.628789</td>\n",
       "      <td>0.600515</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.020441</td>\n",
       "      <td>focal</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.554375</td>\n",
       "      <td>0.510995</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.529640</td>\n",
       "      <td>0.525482</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.927148</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>0.517893</td>\n",
       "      <td>0.472351</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.936010</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0.475711</td>\n",
       "      <td>0.419127</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.937979</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.455430</td>\n",
       "      <td>0.393119</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.446474</td>\n",
       "      <td>0.388626</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.439811</td>\n",
       "      <td>0.381685</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.427604</td>\n",
       "      <td>0.370621</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.421862</td>\n",
       "      <td>0.369891</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.401501</td>\n",
       "      <td>0.353365</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.394969</td>\n",
       "      <td>0.372239</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.931572</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.371486</td>\n",
       "      <td>0.292950</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.931729</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0.351106</td>\n",
       "      <td>0.292895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.945039</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.318235</td>\n",
       "      <td>0.312829</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>cat</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.165233</td>\n",
       "      <td>0.132154</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.945424</td>\n",
       "      <td>dice</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   btch_sz  f1-score  iou_score learn_rate      loss loss_type samp_sz\n",
       "16       3  0.697137   0.664423      0.001  0.016060     focal     250\n",
       "15       3  0.668877   0.641736     0.0003  0.021826     focal     250\n",
       "18       3  0.630676   0.611101        0.1  0.024256     focal     250\n",
       "17       3  0.628789   0.600515       0.01  0.020441     focal     250\n",
       "7        7  0.554375   0.510995        0.1  0.001331       cat     250\n",
       "11       3  0.529640   0.525482        0.1  0.927148      dice     250\n",
       "13       7  0.517893   0.472351      0.001  0.936010      dice     250\n",
       "9        3  0.475711   0.419127      0.001  0.937979      dice     250\n",
       "0        3  0.455430   0.393119     0.0003  0.000659       cat     250\n",
       "5        7  0.446474   0.388626      0.001  0.000731       cat     250\n",
       "1        3  0.439811   0.381685      0.001  0.000882       cat     250\n",
       "4        7  0.427604   0.370621     0.0003  0.000783       cat     250\n",
       "6        7  0.421862   0.369891       0.01  0.001019       cat     250\n",
       "2        3  0.401501   0.353365       0.01  0.001061       cat     250\n",
       "10       3  0.394969   0.372239       0.01  0.931572      dice     250\n",
       "8        3  0.371486   0.292950     0.0003  0.931729      dice     250\n",
       "14       7  0.351106   0.292895       0.01  0.945039      dice     250\n",
       "3        3  0.318235   0.312829        0.1  0.002776       cat     250\n",
       "12       7  0.165233   0.132154     0.0003  0.945424      dice     250"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.sort_values('f1-score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on single set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_path='/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks/weights_history_full/wce_loss/btch_sz_3/lr_0.001/weights/t1dual_inphase_all_orgs_grey_lvl_256_optm_Adam_loss_wce_loss_trn_samp_sz_250_btch_sz_3_lr_0.001_time_2019-11-17_00000006.h5'\n",
    "\n",
    "loss='focal'\n",
    "\n",
    "#gen_test_model(model_gnrl_param:dict,lrn_rate,total_loss,wghts_dir:str,cls_wghts_perc=None)\n",
    "tmp_model=gen_test_model(model_gnrl_params,\n",
    "                                 0.003,\n",
    "                                 loss,fl_path)\n",
    "\n",
    "#test_dataset_visualise=gen_test_dataset(test_data_dir,model_gnrl_params,preprocess_input,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51599768"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_model.count_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing across all parameters please check gen_test_set_df for list filters however!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir='/home/ec2-user/SageMaker/data/unet_data_aug_modified_results/data_aug_all_param_reducd_25perc/cat_focal_loss/btch_sz_3/final_epch_wghts'   \n",
    "\n",
    "tmp_subdir_lst=['50','250','500']\n",
    "\n",
    "for file_sz in tmp_subdir_lst:\n",
    "    \n",
    "    model_dir_gnrl=os.path.join(model_dir,file_sz+'_imgs')\n",
    "    \n",
    "    model_results=get_test_set_df(model_dir_gnrl,test_data_dir,\n",
    "                                  model_gnrl_params,add_info,mode='batch_visualise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing plots of predicted images to masks to determine if kidneys predict more kidneys and vice versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating initial dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_logit_dir='/home/ec2-user/SageMaker/data/unet_predict_logits/500_imgs/500_img/predict_imgs/focal_btch_sz_3_lr_0.0003_epoch_no_99/prob_logits'\n",
    "src_mask_dir='/home/ec2-user/SageMaker/data/500_imgs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the logit files for analysis\n",
    "logit_dir_fl=list(pathlib.Path(src_logit_dir).rglob('*.npy'))\n",
    "#Substirng to filter for masks\n",
    "sub_str_chk=['/masks/','/t1dual_inphase/']\n",
    "lr_rates=['lr_0.001','lr_0.0003','lr_0.01','lr_0.1']\n",
    "loss_type=['focal','dice']\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#Class dictionaries for anlysis\n",
    "org_idx={'l_kidney':0,'liver':1,'r_kidney':2,'spleen':3,'background':-1}\n",
    "cls_dict = {'background':0,'liver':63,'r_kidney':126,'l_kidney':189,'spleen':252}\n",
    "cls_int_inv_dict={org_idx[k]:v for k,v in cls_dict.items()}\n",
    "classes=['l_kidney','liver','r_kidney','spleen']\n",
    "class_values = [cls_dict[cls.lower()] for cls in classes]\n",
    "\n",
    "#Getting mask files for analysis\n",
    "mask_raw_fl=list(pathlib.Path(src_mask_dir).rglob('*.png'))\n",
    "#Creating basename dictionary for file list\n",
    "logit_dir_dict={os.path.splitext(os.path.basename(x))[0]:x for x in logit_dir_fl if str(x).find(loss_type[0])!=-1}\n",
    "\n",
    "\n",
    "#Finding only t1dual images with masks for analysis\n",
    "mask_dir_fl=[x for x in mask_raw_fl if all(str(x).find(y)!=-1 for y in sub_str_chk)]\n",
    "#Creating basename file name dictionary for string matching. \n",
    "bs_nm_msk_dict_pth={os.path.splitext(os.path.basename(x))[0]:x for x in mask_dir_fl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key not found for: pat_id_10_t1dual_inphase_slice_no_1_256grey_lvl_256x256\n"
     ]
    }
   ],
   "source": [
    "final_src_dst_dict={}\n",
    "for k,v in logit_dir_dict.items():\n",
    "    \n",
    "    k_mask_str=k.replace('predict_logit_','')\n",
    "    #Getting final mask directory and logit directory together to run analysis against one another\n",
    "    try:\n",
    "        final_src_dst_dict[v]=bs_nm_msk_dict_pth[k_mask_str]\n",
    "    except KeyError as e:\n",
    "        print('key not found for:',k_mask_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_src_dst_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating F1 score for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_lst=[]\n",
    "for logit_pth,mask_file_pth in final_src_dst_dict.items():\n",
    "    \n",
    "    #Get arrays loaded up \n",
    "    logit_arr=np.load(logit_pth)\n",
    "    logit_arr=logit_binarize(logit_arr)\n",
    "    \n",
    "    # read data\n",
    "    mask = imageio.imread(mask_file_pth)\n",
    "    mask=resize_img_PIL(mask)\n",
    "    mask=gen_binary_mask(mask,class_values)\n",
    "    \n",
    "    for org_nm,idx in org_idx.items():\n",
    "        \n",
    "        if np.sum((mask[:,:,idx],logit_arr[:,:,idx]))!=0:\n",
    "            #print('mask_value',np.sum(mask[:,:,idx]))\n",
    "            #print('logit_value',np.sum(logit_arr[:,:,idx]))\n",
    "            tmp_prec,tmp_recall,tmp_f1,tmp_support=precision_recall_fscore_support(mask[:,:,idx].flatten(),\n",
    "                                                                       logit_arr[:,:,idx].flatten(),\n",
    "                                                                       average='binary')\n",
    "            \n",
    "            tmp_tp,tmp_fp,tmp_tn,tmp_fn=gen_tp_fp_fp_fn(mask[:,:,idx].flatten(),logit_arr[:,:,idx].flatten())\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            tmp_prec,tmp_recall,tmp_f1,tmp_support=('NaN','NaN','NaN','NaN')\n",
    "            tmp_tp,tmp_fp,tmp_tn,tmp_fn=('NaN','NaN','NaN','NaN')\n",
    "        #Get temporary statical dictionary     \n",
    "        tmp_stat_dict=gen_pred_row(mask_file_pth,logit_pth,org_nm,\n",
    "                                   tmp_prec,tmp_recall,tmp_f1,tmp_support,\n",
    "                                   tmp_tp,tmp_fp,tmp_tn,tmp_fn,loss_type='focal',lr_rate=0.001,samp_sz=500)\n",
    "        \n",
    "        \n",
    "        \n",
    "        final_lst.append(tmp_stat_dict) \n",
    "\n",
    "final_df=pd.DataFrame(final_lst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('unet_focal_loss_f1_score_per_class_500_imgs_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/ec2-user/SageMaker/data/per_pat_gnrl_info/per_pat_slc_no.pickle','rb') as fb:\n",
    "    per_pat_per_slc_dict=pickle.load(fb)\n",
    "per_pat_per_slc_dict={int(k):int(v) for k,v in per_pat_per_slc_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_perc_slc_grad(pat_no,slc_no,slc_dict):\n",
    "    try:\n",
    "        \n",
    "        total_no_slcs=slc_dict[pat_no]\n",
    "    except KeyError as e:\n",
    "        ipdb.set_trace()\n",
    "    return slc_no/total_no_slcs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['slice_no']=final_df.patient.str.split('_',expand=True)[7]\n",
    "final_df['pat_id']=final_df.patient.str.extract('(\\d+)')[0]\n",
    "\n",
    "cols_num_conv=['pat_id','false_positive','false_negative','true_positive','true_negative','pat_id','slice_no',\n",
    "              'precision', 'recall','F1_score']\n",
    "final_df[cols_num_conv] = final_df[cols_num_conv].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "final_df['perc_slice_no'] = final_df.apply(lambda x: gen_perc_slc_grad(x.pat_id,\n",
    "                                                                       x.slice_no,\n",
    "                                                                       per_pat_per_slc_dict), axis=1)\n",
    "\n",
    "#slice_test df results \n",
    "final_df['perc_slice_no'] = final_df['perc_slice_no'].apply(pd.to_numeric, errors='coerce')\n",
    "final_df_test=final_df[final_df.pat_id.isin([2,3,8,32,39])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "organ_type\n",
       "l_kidney     98507.0\n",
       "liver        39721.0\n",
       "r_kidney     98850.0\n",
       "spleen      180607.0\n",
       "Name: false_negative, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[final_df.F1_score==0].groupby(['organ_type'])['false_negative'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['l_kidney', 'liver', 'r_kidney', 'spleen', 'background'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_test.organ_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df.F1_score==0].groupby(['organ_type'])['false_negative'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig,axs=plt.subplots(figsize=(20,20))\n",
    "#sns.set(font_scale=1.1)\n",
    "org_str='spleen'\n",
    "g=sns.jointplot(data=final_df_test[(final_df_test.organ_type==org_str)],\n",
    "                x='perc_slice_no',y='F1_score',kind='kde',ylim=(0,1),xlim=(0,1))\n",
    "g.savefig('u_net_focal_loss_lr_0.001_samp_sz_50_'+org_str+'_f1score_wrt_per_slice_no_t1dual.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kidney specific scripting for dice scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidney_mask_concat=merge_arrs(mask[:,:,0],mask[:,:,2])\n",
    "kidney_logit_concat=merge_arrs(logit_arr[:,:,0],logit_arr[:,:,2])\n",
    "tmp_prec,tmp_recall,tmp_f1,tmp_support=precision_recall_fscore_support(kidney_mask_concat.flatten(),\n",
    "                                                                   kidney_logit_concat.flatten(),\n",
    "                                                                   average='binary')\n",
    "tmp_stat_dict=gen_pred_row(mask_file_pth,logit_pth,'both_kidneys',\n",
    "                               tmp_prec,tmp_recall,tmp_f1,tmp_support)\n",
    "final_lst.append(tmp_stat_dict)\n",
    "#Right kidney predicting left kidney\n",
    "tmp_prec,tmp_recall,tmp_f1,tmp_support=precision_recall_fscore_support(mask[:,:,0].flatten(),\n",
    "                                                                   logit_arr[:,:,2].flatten(),\n",
    "                                                                   average='binary')\n",
    "tmp_stat_dict=gen_pred_row(mask_file_pth,logit_pth,'right_kidney_pred_left',\n",
    "                               tmp_prec,tmp_recall,tmp_f1,tmp_support)\n",
    "final_lst.append(tmp_stat_dict)\n",
    "\n",
    "#Left kidney predicting right kidney\n",
    "tmp_prec,tmp_recall,tmp_f1,tmp_support=precision_recall_fscore_support(mask[:,:,2].flatten(),\n",
    "                                                                   logit_arr[:,:,0].flatten(),\n",
    "                                                                   average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('unet_dice_lr_0.0003_epch_69_per_organ_prec_recall_f1score.csv')\n",
    "\n",
    "final_df[['F1_score','precision','recall']]=final_df[['F1_score','precision','recall']].apply(pd.to_numeric,\n",
    "                                                                                             errors='coerce')\n",
    "\n",
    "final_df_agg=final_df.groupby('organ_type')[['F1_score','precision','recall']].mean()\n",
    "final_df_agg.columns=['Dice_score','Precision','Recall']\n",
    "final_df_agg.to_csv('aggregate_unet_dice_lr_0.0003_epch_69__dice_prec_recall_table.csv')\n",
    "final_df_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating logit to actual image predictions side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'SegCaps_multilabels_2019-11-28_11-24-37\n",
    "file_name='SegCaps_multilabels_2019-11-09_01-25-53'\n",
    "src_logit_dir=os.path.join('/home/ec2-user/SageMaker/data/seg_caps_predict_logits',file_name)\n",
    "\n",
    "src_mask_dir='/home/ec2-user/SageMaker/data/500_imgs/'\n",
    "dst_path=os.path.join('/home/ec2-user/SageMaker/results_segcaps_predict_imgs',file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the logit files for analysis\n",
    "logit_dir_fl=list(pathlib.Path(src_logit_dir).rglob('*.mha'))\n",
    "#Substirng to filter for masks\n",
    "sub_str_chk_mask=['/masks/','/t1dual_inphase/']\n",
    "#Substirng to filter for images\n",
    "sub_str_chk_img=['/images/','/t1dual_inphase/']\n",
    "#learning rate and model names to filter logits\n",
    "lr_rates=['lr_0.001','lr_0.0003','lr_0.01','lr_0.1']\n",
    "segcap_model=['SegCaps_multilabels_2019-11-09_01-25-53','SegCaps_multilabels_2019-11-27_20-02-58',\n",
    "             'SegCaps_multilabels_2019-11-28_11-24-37']\n",
    "\n",
    "#Class dictionaries for anlysis\n",
    "org_idx_unet={'l_kidney':0,'liver':1,'r_kidney':2,'spleen':3,'background':4}\n",
    "org_idx_segcaps={'l_kidney':2,'liver':1,'r_kidney':3,'spleen':4,'background':0}\n",
    "cls_dict = {'background':0,'liver':63,'r_kidney':126,'l_kidney':189,'spleen':252}\n",
    "#cls int dict defined for fdining maximum arrays\n",
    "cls_int_inv_dict_unet={org_idx_unet[k]:v for k,v in cls_dict.items()}\n",
    "cls_int_inv_dict_segcaps={org_idx_segcaps[k]:v for k,v in cls_dict.items()}\n",
    "\n",
    "classes=['l_kidney','liver','r_kidney','spleen']\n",
    "class_values = [cls_dict[cls.lower()] for cls in classes]\n",
    "\n",
    "#Getting mask files for analysis\n",
    "mask_raw_fl=list(pathlib.Path(src_mask_dir).rglob('*.png'))\n",
    "#Creating basename dictionary for file list\n",
    "logit_dir_dict={os.path.splitext(os.path.basename(x))[0]:x for x in logit_dir_fl if str(x).find(file_name)!=-1}\n",
    "\n",
    "\n",
    "#Finding only t1dual images with masks for analysis\n",
    "mask_dir_fl=[x for x in mask_raw_fl if all(str(x).find(y)!=-1 for y in sub_str_chk_mask)]\n",
    "#Finding image substring match\n",
    "img_dir_fl=[x for x in mask_raw_fl if all(str(x).find(y)!=-1 for y in sub_str_chk_img)]\n",
    "#Creating basename file name dictionary for string matching. \n",
    "bs_nm_msk_dict_pth={os.path.splitext(os.path.basename(x))[0]:x for x in mask_dir_fl}\n",
    "bs_nm_img_dict_pth={os.path.basename(x):x for x in img_dir_fl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key not found for: pat_id_10_t1dual_inphase_slice_no_1_256grey_lvl_256x256\n"
     ]
    }
   ],
   "source": [
    "final_src_dst_dict={}\n",
    "for k,v in logit_dir_dict.items():\n",
    "    \n",
    "    k_mask_str=k.replace('_prediction','')\n",
    "    #Getting final mask directory and logit directory together to run analysis against one another\n",
    "    try:\n",
    "        final_src_dst_dict[v]=bs_nm_msk_dict_pth[k_mask_str]\n",
    "    except KeyError as e:\n",
    "        print('key not found for:',k_mask_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(logit_arr[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(logit_arr[:,:,0].flatten())\n",
    "plt.xlabel('probability map value')\n",
    "plt.ylabel('occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_arr_logit_background=None\n",
    "for logit_pth,mask_file_pth in final_src_dst_dict.items():\n",
    "    #Get arrays loaded up \n",
    "    logit_arr,_=load(str(logit_pth))\n",
    "    \n",
    "    back_arr=logit_arr[:,:,0].flatten()\n",
    "    if concat_arr_logit_background is None:\n",
    "        concat_arr_logit_background=back_arr\n",
    "    else:\n",
    "        concat_arr_logit_background=np.concatenate((concat_arr_logit_background,back_arr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(concat_arr_logit_background,density=True,bins=20)\n",
    "plt.xticks(np.arange(0, 1, step=0.05),rotation=45)\n",
    "\n",
    "plt.xlabel('probability map value')\n",
    "plt.ylabel('occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_src_dst_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index slicing dictionary for visualisation. first index in tuple is logit 2ns index is mask. \n",
    "mask_logit_idx_slc_segcaps={'background':(0,4),'l_kidney':(3,0),'r_kidney':(2,2),'liver':(1,1),'spleen':(4,3)}\n",
    "mask_logit_idx_slc_unet={'background':(4,4),'l_kidney':(0,0),'r_kidney':(2,2),'liver':(1,1),'spleen':(3,3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lst=[]\n",
    "for logit_pth,mask_file_pth in final_src_dst_dict.items():\n",
    "    \n",
    "    \n",
    "    #Get arrays loaded up \n",
    "    logit_arr,_=load(str(logit_pth))\n",
    "    break\n",
    "    logit_arr=logit_binarize(logit_arr)\n",
    "    #logit_arr=reset_logit_int(logit_arr,cls_int_inv_dict_segcaps)\n",
    "    pr_mask=np.rot90(logit_arr,3)\n",
    "\n",
    "    #pr_mask_arr=logit_binarize(np.array(rot_img))\n",
    "    \n",
    "    #tmp_img_path\n",
    "    img_nm=os.path.basename(mask_file_pth)\n",
    "    tmp_img=imageio.imread(bs_nm_img_dict_pth[img_nm])\n",
    "    \n",
    "    dst_img_path=os.path.join(dst_path,'binary_predict_'+img_nm)\n",
    "    \n",
    "    # read data\n",
    "    mask = imageio.imread(mask_file_pth)\n",
    "    mask=resize_img_PIL(mask)\n",
    "    gt_mask=gen_binary_mask(mask,class_values)\n",
    "    \n",
    "    visualize(dst_img_path,\n",
    "            image=tmp_img,\n",
    "            gt_mask_l_kidney=gt_mask[:,:,mask_logit_idx_slc_segcaps['l_kidney'][1]],\n",
    "            pr_mask_l_kidney=pr_mask[:,:,mask_logit_idx_slc_segcaps['l_kidney'][0]],\n",
    "            gt_mask_liver=gt_mask[:,:,mask_logit_idx_slc_segcaps['liver'][1]],\n",
    "            pr_mask_liver=pr_mask[:,:,mask_logit_idx_slc_segcaps['liver'][0]],\n",
    "            gt_mask_r_kidney=gt_mask[:,:,mask_logit_idx_slc_segcaps['r_kidney'][1]],\n",
    "            pr_mask_r_kidney=pr_mask[:,:,mask_logit_idx_slc_segcaps['r_kidney'][0]],\n",
    "            gt_mask_spleen=gt_mask[:,:,mask_logit_idx_slc_segcaps['spleen'][1]],\n",
    "            pr_mask_spleen=pr_mask[:,:,mask_logit_idx_slc_segcaps['spleen'][0]],\n",
    "            gt_mask_background=gt_mask[:,:,mask_logit_idx_slc_segcaps['background'][1]],\n",
    "            pr_mask_background=pr_mask[:,:,mask_logit_idx_slc_segcaps['background'][0]],\n",
    "        )  \n",
    "    \n",
    "    \n",
    "    for org_nm,idx in org_idx_segcaps.items():\n",
    "        \n",
    "        if np.sum((gt_mask[:,:,idx],pr_mask[:,:,idx]))!=0:\n",
    "            #print('mask_value',np.sum(mask[:,:,idx]))\n",
    "            #print('logit_value',np.sum(logit_arr[:,:,idx]))\n",
    "            tmp_prec,tmp_recall,tmp_f1,tmp_support=precision_recall_fscore_support(gt_mask[:,:,idx].flatten(),\n",
    "                                                                       pr_mask[:,:,idx].flatten(),\n",
    "                                                                       average='binary')\n",
    "            \n",
    "            tmp_tp,tmp_fp,tmp_tn,tmp_fn=gen_tp_fp_fp_fn(gt_mask[:,:,idx].flatten(),pr_mask[:,:,idx].flatten())\n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            tmp_prec,tmp_recall,tmp_f1,tmp_support=('NaN','NaN','NaN','NaN')\n",
    "            tmp_tp,tmp_fp,tmp_tn,tmp_fn=('NaN','NaN','NaN','NaN')\n",
    "        #Get temporary statical dictionary     \n",
    "        tmp_stat_dict=gen_pred_row(mask_file_pth,logit_pth,org_nm,\n",
    "                                   tmp_prec,tmp_recall,tmp_f1,tmp_support,\n",
    "                                   tmp_tp,tmp_fp,tmp_tn,tmp_fn,loss_type='WCE',lr_rate=0.1,samp_sz=250)\n",
    "        \n",
    "        \n",
    "        \n",
    "        final_lst.append(tmp_stat_dict) \n",
    "\n",
    "final_df_segcaps=pd.DataFrame(final_lst)\n",
    "final_df_segcaps.to_csv(os.path.join(dst_path,file_name+'df_f1score_re_prec_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "y_true_arr=None\n",
    "y_pred_arr=None\n",
    "\n",
    "for logit_pth,mask_file_pth in final_src_dst_dict.items():\n",
    "    \n",
    "    #Get arrays loaded up \n",
    "    logit_arr=np.load(logit_pth)\n",
    "    logit_arr=logit_binarize(logit_arr)\n",
    "    logit_arr=reset_logit_int(logit_arr,cls_int_inv_dict)\n",
    "    logit_arr=comp_logit(logit_arr)\n",
    "    y_pred_arr=concat_flat_arr(logit_arr.flatten(),y_pred_arr)\n",
    "    # read data\n",
    "    mask = imageio.imread(mask_file_pth)\n",
    "    mask=resize_img_PIL(mask)\n",
    "    y_true_arr=concat_flat_arr(mask.flatten(),y_true_arr)\n",
    "#Generating temporary confusion matrix     \n",
    "tmp_conf_mat=ConfusionMatrix(y_true_arr,y_pred_arr)\n",
    "tmp_conf_mat_df=tmp_conf_mat.to_dataframe()\n",
    "#rename analysis\n",
    "tmp_conf_mat_df=tmp_conf_mat.to_dataframe()\n",
    "tmp_conf_mat_df.rename({0.0:'Background',\n",
    "                       63:'liver',\n",
    "                       126:'r_kidney',\n",
    "                       189:'l_kidney',\n",
    "                       252:'spleen'},axis=0,inplace=True)\n",
    "tmp_conf_mat_df.rename({0.0:'Background',\n",
    "                       63:'liver',\n",
    "                       126:'r_kidney',\n",
    "                       189:'l_kidney',\n",
    "                       252:'spleen'},axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_conf_mat_df.to_csv('unet_focal_loss_lr_0.001_epch_no99_samp_sz_500_conf_mat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Background</th>\n",
       "      <th>liver</th>\n",
       "      <th>r_kidney</th>\n",
       "      <th>l_kidney</th>\n",
       "      <th>spleen</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Background</th>\n",
       "      <td>25154182</td>\n",
       "      <td>45349</td>\n",
       "      <td>16888</td>\n",
       "      <td>28015</td>\n",
       "      <td>13282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liver</th>\n",
       "      <td>83929</td>\n",
       "      <td>820693</td>\n",
       "      <td>955</td>\n",
       "      <td>0</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_kidney</th>\n",
       "      <td>6329</td>\n",
       "      <td>803</td>\n",
       "      <td>79487</td>\n",
       "      <td>12231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_kidney</th>\n",
       "      <td>4713</td>\n",
       "      <td>1</td>\n",
       "      <td>825</td>\n",
       "      <td>92801</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spleen</th>\n",
       "      <td>39390</td>\n",
       "      <td>9204</td>\n",
       "      <td>627</td>\n",
       "      <td>953</td>\n",
       "      <td>130433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   Background   liver  r_kidney  l_kidney  spleen\n",
       "Actual                                                    \n",
       "Background    25154182   45349     16888     28015   13282\n",
       "liver            83929  820693       955         0     823\n",
       "r_kidney          6329     803     79487     12231       0\n",
       "l_kidney          4713       1       825     92801     167\n",
       "spleen           39390    9204       627       953  130433"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_conf_mat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/Masters-Thesis-UNet-repository/jupyter_notebooks'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_flat_arr(arr:np.ndarray,concat_arr)->np.ndarray:\n",
    "    \"\"\"The purpose of this method is to concat an array together with an arra yor none type\n",
    "    primarily this function is used as an aggregatoin function at the end of a for loop. \"\"\"\n",
    "    if concat_arr is None:\n",
    "        return arr\n",
    "    else:\n",
    "        #ipdb.set_trace()\n",
    "        concat_arr=np.concatenate((concat_arr,arr))\n",
    "        return concat_arr\n",
    "    \n",
    "\n",
    "def reset_logit_int(logit:np.ndarray,cls_lbl_dict)->np.ndarray:\n",
    "    \"\"\"The purpose of this method is to compress a logit down into a single layer array for analysis \"\"\"\n",
    "    \n",
    "    for k,v in cls_lbl_dict.items():\n",
    "        logit[:,:,k]=np.where(logit[:,:,k]==1,v,0)\n",
    "    \n",
    "    return logit\n",
    "\n",
    "def comp_logit(logit:np.ndarray)->np.ndarray:\n",
    "    return np.amax(logit,axis=2)\n",
    "        \n",
    "    \n",
    "def gen_pred_row(mask_file_pth:str,logit_pth:str,\n",
    "                 org_nm:str,tmp_prec,tmp_recall,tmp_f1,\n",
    "                 tmp_support,tmp_tp,tmp_fp,tmp_tn,tmp_fn,\n",
    "                loss_type=None,lr_rate=None,samp_sz=None)->dict:\n",
    "    \n",
    "    final_dict={'patient':os.path.splitext(os.path.basename(mask_file_pth))[0],'samp_sz':samp_sz,\n",
    "                          'loss':loss_type,\n",
    "                          'learn_rate':lr_rate,\n",
    "                          'organ_type':org_nm,\n",
    "                          'precision':tmp_prec,'recall':tmp_recall,'F1_score':tmp_f1,\n",
    "                          'support_no':tmp_support,'true_positive':tmp_tp,'false_positive':tmp_fp,\n",
    "                            'true_negative':tmp_tn,'false_negative':tmp_fn}\n",
    "    if loss_type is None:\n",
    "        final_dict['loss']=[x for x in loss_type if str(logit_pth).find(x)!=-1][0]\n",
    "    if lr_rate is None:\n",
    "        final_dict['learn_rate']=[x for x in lr_rates if str(logit_pth).find(x)!=-1][0]\n",
    "    \n",
    "    return final_dict\n",
    "\n",
    "def gen_tp_fp_fp_fn(y_true,y_pred):\n",
    "    \n",
    "    #Y true y predict true positive and negatives\n",
    "    pos_y_true=(y_true==1)\n",
    "    pos_y_pred=(y_pred==1)\n",
    "    neg_y_true=(y_true==0)\n",
    "    neg_y_pred=(y_pred==0)\n",
    "    #Generating false positive values \n",
    "    true_pos=len(np.where(pos_y_true&pos_y_pred)[0])\n",
    "    false_pos=len(np.where(pos_y_pred&neg_y_true)[0])\n",
    "    #Generating true negatives and false negatives\n",
    "    true_neg=len(np.where(neg_y_true&neg_y_pred)[0])\n",
    "    false_neg=len(np.where(neg_y_pred&pos_y_true)[0])\n",
    "    \n",
    "    return true_pos,false_pos,true_neg,false_neg\n",
    "\n",
    "def gen_binary_mask(mask:np.ndarray,class_values:list,reord_stack=None)->np.ndarray:\n",
    "    \n",
    "    # extract certain classes from mask (e.g. cars)\n",
    "    masks = [(mask == v) for v in class_values]\n",
    "    mask = np.stack(masks, axis=-1).astype('float')\n",
    "\n",
    "    # add background if mask is not binary\n",
    "    if mask.shape[-1] != 1:\n",
    "        background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "        mask = np.concatenate((mask, background), axis=-1)\n",
    "    if reord_stack is None:\n",
    "        \n",
    "        return mask\n",
    "    else:\n",
    "        mask=np.transpose(mask,reord_stack)\n",
    "\n",
    "def merge_arrs(arr1,arr2):\n",
    "    return np.where(arr2>0,1,arr1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
